{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d06f4599",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.lang.en import English\n",
    "from spacy.pipeline import EntityRuler\n",
    "import json\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1bbb8361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['El Corrido de Gregorio Cortez- variant X\\n\\nIn the country of Karnes, \\nLook what has happened; \\nThe Major Sheriff died,\\nLeaving Román badly wounded.\\n\\nIt must have been two in the \\n\\tafternnon\\nWhen people arrived;\\nThey said to one another,\\n“It is not known who killed him.”\\n\\nThey went around asking questions,\\nAbout half an hour afterward, \\nThey found that the wrongdoer\\nHad been Gregorio Cortez.\\n\\nNow they have outlawed Cortez,\\nThroughout the whole state;\\nLet him be taken, dead or alive; \\nHe has killed several men.\\n\\nThey said Gregorio Cortez, \\nWith his pistol in his hand,\\n“I don’t regret that I killed him; \\nI regret my brother’s death.”\\n\\nThen said Gregorio Cortez, \\nAnd his soul was all aflame, \\n“I don’t regret that I killed him;\\nA man must defend himself.”\\n\\nThe Americans were coming, \\nThey were whiter than a dove, \\nFrom the fear that they had \\nOf Cortez and of his pistol. \\n\\nThen the Americans said, \\nThen they said fearfully,\\n“Come, let us follow the trail;\\nThe wrongdoer is Cortez.”\\n\\nThey set the bloodhounds on him, \\nSo they could follow his trail, \\nBut trying to overtake  Cortez\\nWas like following a star.. \\n\\nHe struck out for Gonzales\\nWithout showing any fear,\\n“Follow me, cowardly rangers, \\nI am Gregorio Cortez.”\\n\\nFrom Belmont he went to the \\n\\tranch,  \\nThey succeeded in surrounding \\n\\thim, \\nQuite a few more than three hundred, \\nBut there he jumped their corral. \\n\\nWhen he jumped their corral, \\nAccording to what we hear,\\nThey got into a gunfight,\\nAnd he killed them another sheriff, \\n\\nThen said Gregorio Cortez, \\nWith his pistol in his hand, \\n“Don’t run, you cowardly rangers, \\nFrom just one Mexican.”\\n\\nGregorio Cortez went out, \\nHe went towards Laredo\\nThey decided not to follow \\nBecause they were afraid of him.\\n\\nThen said Gregorio Cortez, \\n“What is the use of your scheming?\\nYou cannot catch me,\\nEven with those bloodhounds.”\\n\\nThen the Americans said, \\n“If we catch you with him, what \\nShall we do?\\nIf we fight him man to man, \\nVery few of us will return.”\\n\\nOver by El Encinal, \\nAccording to what we hear, \\nThey made him a corral, \\nAnd he killed them another sheriff. \\n\\nThen said Gregorio Cortez, \\nShooting out a lot of bullets,\\n“I have weathered thunderstorms;\\nThis little mist doesn’t bother me.”\\n\\nNow he has met a Mexican;\\nHe says to him haughtily,\\n“Tell me the news;\\nI am Gregorio Cortez.” \\n\\n“It is said that because of me \\nMany people have been killed;\\nI will surrender now\\nBecause such things are not right.”\\n\\nCortez says to Jesús,\\n“At last you are going to see it;\\nGo tell the rangers\\nTo come and arrest me.”\\n\\nAll the rangers were coming, \\nComing so fast they even flew, \\nFor they wanted to get \\nThe thousand dollars they were \\noffered. \\n\\nWhen they surrounded the house, \\nCortez suddenly appeared before\\n\\tthem, \\n“You will take me if I’m willing, \\nBut not any other way.”\\n\\nThen the Major Sheriff said, \\nAs if he was going to cry, \\n“Cortez, hand over your weapons;\\nWe are not going to kill.”\\n\\nThen said Gregorio Cortez,\\nShouting to them in a loud voice,\\n“I won’t surrender my arms\\nUntil I am in a cell.”\\n\\nThen said Gregorio Cortez,\\nHe said in his godly voice, \\n“I won’t surrender my arms\\nUntil I’m inside a jail.”\\n\\nNow they have taken Cortez,\\nNow matters are at an end, \\nHis poor family\\nAre suffering in their hearts.\\n\\nNow with this I say farewell, \\nIn the shade of a cypress treel;\\nThis the end of singing \\nOf the ballad of Cortez.']\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "[E109] Component 'ner' could not be run. Did you forget to call `initialize()`?",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\dmlpz\\anaconda3\\envs\\Greg\\lib\\site-packages\\spacy\\language.py:1020\u001b[0m, in \u001b[0;36mLanguage.__call__\u001b[1;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[0;32m   1019\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1020\u001b[0m     doc \u001b[39m=\u001b[39m proc(doc, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcomponent_cfg\u001b[39m.\u001b[39mget(name, {}))  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m   1021\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m   1022\u001b[0m     \u001b[39m# This typically happens if a component is not initialized\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\dmlpz\\anaconda3\\envs\\Greg\\lib\\site-packages\\spacy\\pipeline\\trainable_pipe.pyx:56\u001b[0m, in \u001b[0;36mspacy.pipeline.trainable_pipe.TrainablePipe.__call__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\dmlpz\\anaconda3\\envs\\Greg\\lib\\site-packages\\spacy\\util.py:1630\u001b[0m, in \u001b[0;36mraise_error\u001b[1;34m(proc_name, proc, docs, e)\u001b[0m\n\u001b[0;32m   1629\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mraise_error\u001b[39m(proc_name, proc, docs, e):\n\u001b[1;32m-> 1630\u001b[0m     \u001b[39mraise\u001b[39;00m e\n",
      "File \u001b[1;32mc:\\Users\\dmlpz\\anaconda3\\envs\\Greg\\lib\\site-packages\\spacy\\pipeline\\trainable_pipe.pyx:52\u001b[0m, in \u001b[0;36mspacy.pipeline.trainable_pipe.TrainablePipe.__call__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\dmlpz\\anaconda3\\envs\\Greg\\lib\\site-packages\\spacy\\pipeline\\transition_parser.pyx:250\u001b[0m, in \u001b[0;36mspacy.pipeline.transition_parser.Parser.predict\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\dmlpz\\anaconda3\\envs\\Greg\\lib\\site-packages\\spacy\\pipeline\\transition_parser.pyx:265\u001b[0m, in \u001b[0;36mspacy.pipeline.transition_parser.Parser.greedy_parse\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\dmlpz\\anaconda3\\envs\\Greg\\lib\\site-packages\\thinc\\model.py:315\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    312\u001b[0m \u001b[39m\"\"\"Call the model's `forward` function with `is_train=False`, and return\u001b[39;00m\n\u001b[0;32m    313\u001b[0m \u001b[39monly the output, instead of the `(output, callback)` tuple.\u001b[39;00m\n\u001b[0;32m    314\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 315\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func(\u001b[39mself\u001b[39;49m, X, is_train\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\dmlpz\\anaconda3\\envs\\Greg\\lib\\site-packages\\spacy\\ml\\tb_framework.py:33\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(model, X, is_train):\n\u001b[1;32m---> 33\u001b[0m     step_model \u001b[39m=\u001b[39m ParserStepModel(\n\u001b[0;32m     34\u001b[0m         X,\n\u001b[0;32m     35\u001b[0m         model\u001b[39m.\u001b[39;49mlayers,\n\u001b[0;32m     36\u001b[0m         unseen_classes\u001b[39m=\u001b[39;49mmodel\u001b[39m.\u001b[39;49mattrs[\u001b[39m\"\u001b[39;49m\u001b[39munseen_classes\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m     37\u001b[0m         train\u001b[39m=\u001b[39;49mis_train,\n\u001b[0;32m     38\u001b[0m         has_upper\u001b[39m=\u001b[39;49mmodel\u001b[39m.\u001b[39;49mattrs[\u001b[39m\"\u001b[39;49m\u001b[39mhas_upper\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m     39\u001b[0m     )\n\u001b[0;32m     41\u001b[0m     \u001b[39mreturn\u001b[39;00m step_model, step_model\u001b[39m.\u001b[39mfinish_steps\n",
      "File \u001b[1;32mc:\\Users\\dmlpz\\anaconda3\\envs\\Greg\\lib\\site-packages\\spacy\\ml\\parser_model.pyx:217\u001b[0m, in \u001b[0;36mspacy.ml.parser_model.ParserStepModel.__init__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\dmlpz\\anaconda3\\envs\\Greg\\lib\\site-packages\\thinc\\model.py:291\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    289\u001b[0m \u001b[39m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[0;32m    290\u001b[0m \u001b[39mcallback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 291\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func(\u001b[39mself\u001b[39;49m, X, is_train\u001b[39m=\u001b[39;49mis_train)\n",
      "File \u001b[1;32mc:\\Users\\dmlpz\\anaconda3\\envs\\Greg\\lib\\site-packages\\thinc\\layers\\chain.py:54\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mlayers:\n\u001b[1;32m---> 54\u001b[0m     Y, inc_layer_grad \u001b[39m=\u001b[39m layer(X, is_train\u001b[39m=\u001b[39;49mis_train)\n\u001b[0;32m     55\u001b[0m     callbacks\u001b[39m.\u001b[39mappend(inc_layer_grad)\n",
      "File \u001b[1;32mc:\\Users\\dmlpz\\anaconda3\\envs\\Greg\\lib\\site-packages\\thinc\\model.py:291\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    289\u001b[0m \u001b[39m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[0;32m    290\u001b[0m \u001b[39mcallback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 291\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func(\u001b[39mself\u001b[39;49m, X, is_train\u001b[39m=\u001b[39;49mis_train)\n",
      "File \u001b[1;32mc:\\Users\\dmlpz\\anaconda3\\envs\\Greg\\lib\\site-packages\\thinc\\layers\\chain.py:54\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mlayers:\n\u001b[1;32m---> 54\u001b[0m     Y, inc_layer_grad \u001b[39m=\u001b[39m layer(X, is_train\u001b[39m=\u001b[39;49mis_train)\n\u001b[0;32m     55\u001b[0m     callbacks\u001b[39m.\u001b[39mappend(inc_layer_grad)\n",
      "    \u001b[1;31m[... skipping similar frames: Model.__call__ at line 291 (1 times)]\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\dmlpz\\anaconda3\\envs\\Greg\\lib\\site-packages\\thinc\\layers\\chain.py:54\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mlayers:\n\u001b[1;32m---> 54\u001b[0m     Y, inc_layer_grad \u001b[39m=\u001b[39m layer(X, is_train\u001b[39m=\u001b[39;49mis_train)\n\u001b[0;32m     55\u001b[0m     callbacks\u001b[39m.\u001b[39mappend(inc_layer_grad)\n",
      "File \u001b[1;32mc:\\Users\\dmlpz\\anaconda3\\envs\\Greg\\lib\\site-packages\\thinc\\model.py:291\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    289\u001b[0m \u001b[39m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[0;32m    290\u001b[0m \u001b[39mcallback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 291\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func(\u001b[39mself\u001b[39;49m, X, is_train\u001b[39m=\u001b[39;49mis_train)\n",
      "File \u001b[1;32mc:\\Users\\dmlpz\\anaconda3\\envs\\Greg\\lib\\site-packages\\thinc\\layers\\with_array.py:30\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, Xseq, is_train)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(Xseq, Ragged):\n\u001b[1;32m---> 30\u001b[0m     \u001b[39mreturn\u001b[39;00m _ragged_forward(\n\u001b[0;32m     31\u001b[0m         cast(Model[Ragged, Ragged], model), cast(Ragged, Xseq), is_train\n\u001b[0;32m     32\u001b[0m     )\n\u001b[0;32m     33\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(Xseq, Padded):\n",
      "File \u001b[1;32mc:\\Users\\dmlpz\\anaconda3\\envs\\Greg\\lib\\site-packages\\thinc\\layers\\with_array.py:90\u001b[0m, in \u001b[0;36m_ragged_forward\u001b[1;34m(model, Xr, is_train)\u001b[0m\n\u001b[0;32m     89\u001b[0m layer: Model[ArrayXd, ArrayXd] \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mlayers[\u001b[39m0\u001b[39m]\n\u001b[1;32m---> 90\u001b[0m Y, get_dX \u001b[39m=\u001b[39m layer(Xr\u001b[39m.\u001b[39;49mdataXd, is_train)\n\u001b[0;32m     92\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbackprop\u001b[39m(dYr: Ragged) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Ragged:\n",
      "File \u001b[1;32mc:\\Users\\dmlpz\\anaconda3\\envs\\Greg\\lib\\site-packages\\thinc\\model.py:291\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    289\u001b[0m \u001b[39m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[0;32m    290\u001b[0m \u001b[39mcallback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 291\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func(\u001b[39mself\u001b[39;49m, X, is_train\u001b[39m=\u001b[39;49mis_train)\n",
      "File \u001b[1;32mc:\\Users\\dmlpz\\anaconda3\\envs\\Greg\\lib\\site-packages\\thinc\\layers\\concatenate.py:44\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(model: Model[InT, OutT], X: InT, is_train: \u001b[39mbool\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m---> 44\u001b[0m     Ys, callbacks \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39m[layer(X, is_train\u001b[39m=\u001b[39mis_train) \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mlayers])\n\u001b[0;32m     45\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(Ys[\u001b[39m0\u001b[39m], \u001b[39mlist\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\dmlpz\\anaconda3\\envs\\Greg\\lib\\site-packages\\thinc\\layers\\concatenate.py:44\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(model: Model[InT, OutT], X: InT, is_train: \u001b[39mbool\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m---> 44\u001b[0m     Ys, callbacks \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39m[layer(X, is_train\u001b[39m=\u001b[39;49mis_train) \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mlayers])\n\u001b[0;32m     45\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(Ys[\u001b[39m0\u001b[39m], \u001b[39mlist\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\dmlpz\\anaconda3\\envs\\Greg\\lib\\site-packages\\thinc\\model.py:291\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    289\u001b[0m \u001b[39m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[0;32m    290\u001b[0m \u001b[39mcallback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 291\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func(\u001b[39mself\u001b[39;49m, X, is_train\u001b[39m=\u001b[39;49mis_train)\n",
      "File \u001b[1;32mc:\\Users\\dmlpz\\anaconda3\\envs\\Greg\\lib\\site-packages\\thinc\\layers\\chain.py:54\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mlayers:\n\u001b[1;32m---> 54\u001b[0m     Y, inc_layer_grad \u001b[39m=\u001b[39m layer(X, is_train\u001b[39m=\u001b[39;49mis_train)\n\u001b[0;32m     55\u001b[0m     callbacks\u001b[39m.\u001b[39mappend(inc_layer_grad)\n",
      "File \u001b[1;32mc:\\Users\\dmlpz\\anaconda3\\envs\\Greg\\lib\\site-packages\\thinc\\model.py:291\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    289\u001b[0m \u001b[39m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[0;32m    290\u001b[0m \u001b[39mcallback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 291\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func(\u001b[39mself\u001b[39;49m, X, is_train\u001b[39m=\u001b[39;49mis_train)\n",
      "File \u001b[1;32mc:\\Users\\dmlpz\\anaconda3\\envs\\Greg\\lib\\site-packages\\thinc\\layers\\hashembed.py:61\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, ids, is_train)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[0;32m     59\u001b[0m     model: Model[InT, OutT], ids: Ints1d, is_train: \u001b[39mbool\u001b[39m\n\u001b[0;32m     60\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m---> 61\u001b[0m     vectors \u001b[39m=\u001b[39m cast(Floats2d, model\u001b[39m.\u001b[39;49mget_param(\u001b[39m\"\u001b[39;49m\u001b[39mE\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n\u001b[0;32m     62\u001b[0m     nV \u001b[39m=\u001b[39m vectors\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\dmlpz\\anaconda3\\envs\\Greg\\lib\\site-packages\\thinc\\model.py:216\u001b[0m, in \u001b[0;36mModel.get_param\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_params\u001b[39m.\u001b[39mhas_param(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mid, name):\n\u001b[1;32m--> 216\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\n\u001b[0;32m    217\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mParameter \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m for model \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m has not been allocated yet.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    218\u001b[0m     )\n\u001b[0;32m    219\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_params\u001b[39m.\u001b[39mget_param(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mid, name)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"Parameter 'E' for model 'hashembed' has not been allocated yet.\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 66\u001b[0m\n\u001b[0;32m     64\u001b[0m segment \u001b[39m=\u001b[39m segment\u001b[39m.\u001b[39mstrip()\n\u001b[0;32m     65\u001b[0m segment \u001b[39m=\u001b[39m segment\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 66\u001b[0m results \u001b[39m=\u001b[39m test_model(nlp, segment)\n\u001b[0;32m     67\u001b[0m \u001b[39mfor\u001b[39;00m result \u001b[39min\u001b[39;00m results:\n\u001b[0;32m     68\u001b[0m     hits\u001b[39m.\u001b[39mappend(result)\n",
      "Cell \u001b[1;32mIn[43], line 41\u001b[0m, in \u001b[0;36mtest_model\u001b[1;34m(model, text)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtest_model\u001b[39m(model, text):\n\u001b[1;32m---> 41\u001b[0m     doc \u001b[39m=\u001b[39m nlp(text)\n\u001b[0;32m     42\u001b[0m     results \u001b[39m=\u001b[39m []\n\u001b[0;32m     43\u001b[0m     \u001b[39mfor\u001b[39;00m ent \u001b[39min\u001b[39;00m doc\u001b[39m.\u001b[39ments:\n",
      "File \u001b[1;32mc:\\Users\\dmlpz\\anaconda3\\envs\\Greg\\lib\\site-packages\\spacy\\language.py:1023\u001b[0m, in \u001b[0;36mLanguage.__call__\u001b[1;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[0;32m   1020\u001b[0m     doc \u001b[39m=\u001b[39m proc(doc, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcomponent_cfg\u001b[39m.\u001b[39mget(name, {}))  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m   1021\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m   1022\u001b[0m     \u001b[39m# This typically happens if a component is not initialized\u001b[39;00m\n\u001b[1;32m-> 1023\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(Errors\u001b[39m.\u001b[39mE109\u001b[39m.\u001b[39mformat(name\u001b[39m=\u001b[39mname)) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[0;32m   1024\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m   1025\u001b[0m     error_handler(name, proc, [doc], e)\n",
      "\u001b[1;31mValueError\u001b[0m: [E109] Component 'ner' could not be run. Did you forget to call `initialize()`?"
     ]
    }
   ],
   "source": [
    "def load_data(file):\n",
    "    #print(file)\n",
    "    with open(file, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "        #print(data)\n",
    "        return(data)\n",
    "\n",
    "def save_data (file, data):\n",
    "    with open (file, \"w\", encoding='utf-8') as f:\n",
    "        print(file) \n",
    "        json.dump(data, f, indent=4)\n",
    "        print(data)\n",
    "\n",
    "#training model\n",
    "def create_training_data(file, type):\n",
    "    #print(type)\n",
    "    data = load_data(file)\n",
    "    #print(file)\n",
    "    patterns=[]\n",
    "    for item in data:\n",
    "        #print(item)\n",
    "        #print(data)\n",
    "        pattern = {\n",
    "                    \"label\":type,\n",
    "                    \"pattern\": item\n",
    "                    }\n",
    "        #print(pattern)\n",
    "        patterns.append(pattern)\n",
    "        #print(patterns)\n",
    "    return(patterns)\n",
    "\n",
    "\n",
    "def generate_rules(patterns):\n",
    "    nlp = English()\n",
    "    ruler = EntityRuler(nlp)\n",
    "    ruler.add_patterns(patterns)\n",
    "    nlp.add_pipe('ner')\n",
    "    nlp.to_disk(\"tx_ner\")\n",
    "\n",
    "def test_model(model, text):\n",
    "    doc = nlp(text)\n",
    "    results = []\n",
    "    for ent in doc.ents:\n",
    "        results.append(ent.text)\n",
    "    return(results)\n",
    "\n",
    "patterns = create_training_data(\"../Corridos/data/TexasMunicipalities.json\", \"GPE\")\n",
    "generate_rules(patterns)\n",
    "#print (patterns)\n",
    "\n",
    "nlp = spacy.load(\"tx_ner\")\n",
    "ie_data = {}\n",
    "with open (\"corrido corpus\\ElCorridodeGregorioCortez_X.txt\", \"r\", encoding='utf-8')as f:\n",
    "    text = f.read()\n",
    "\n",
    "    corridos = text.split(\"GregorioCortez\")\n",
    "    print(corridos)\n",
    "    for corrido in corridos:\n",
    "        corrido_num, corrido_title = corrido.split(\"\\n\\n\")[0:2]\n",
    "        corrido_num = corrido_num.strip()\n",
    "        segments = corrido.split(\"\\n\\n\")[2:]\n",
    "        hits = []\n",
    "        for segment in segments:\n",
    "            segment = segment.strip()\n",
    "            segment = segment.replace(\"\\n\", \" \")\n",
    "            results = test_model(nlp, segment)\n",
    "            for result in results:\n",
    "                hits.append(result)\n",
    "        ie_data[corrido_num] = hits\n",
    "        print(ie_data)\n",
    "\n",
    "save_data(\"../Corridos/data/tx_mun_data.json\", ie_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4920138c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rules based ner\n",
    "#1st open txt file from the corridos corpus folder\n",
    "with open (\"../Corridos/corrido corpus/ElCorridodeGregorioCortez_X.txt\", 'r', encoding='utf-8') as f:\n",
    "    text=f.read().split(\"\\n\") #parsing a section of the song to work with.\n",
    "    print(text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d04c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "tx_municipalities_ner = []\n",
    "#import data: tx_places.json\n",
    "with open (\"./data/TexasMunicipalities.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    tx_mun = json.load(f)\n",
    "    print(tx_mun)\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6961bc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#break down the text by segement by segement\n",
    "for segment in text:\n",
    "    segment = segment.strip()\n",
    "    #segment = segment.lower()\n",
    "    segment = segment.replace(\"\\n\", \" \")\n",
    "    #print(segment)\n",
    "\n",
    "#remove all puncation for the text\n",
    "    punc = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~''' \n",
    "# Removing punctuations in string\n",
    "# Using loop + punctuation string\n",
    "    for ele in segment:\n",
    "        if ele in punc:\n",
    "            segment = segment.replace(ele, \"\")\n",
    "    print (segment)\n",
    "#convert segment into a list of words\n",
    "    words =segment.split()\n",
    "    #print(words)\n",
    "    i=0\n",
    "    for word in words:\n",
    "        if word in tx_mun:\n",
    "            if words[i-1][0].isupper():\n",
    "                print(f\"Found Municipalities): {words[i-1]} {word}\")\n",
    "            else:\n",
    "                print(f\"Found Municipalities: {word}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c022c596",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Greg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "c33b8046986a03aa44ef4ea500a2630dcd79ff60fec54402ff1309c4dcbd3e63"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
