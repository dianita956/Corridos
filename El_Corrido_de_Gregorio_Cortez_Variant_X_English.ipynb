{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {}
      }
     }
    }
   },
   "source": [
    "# El corrido de Gregorio Cortez\n",
    "\n",
    "## Mapping the manhunt of Rio Grande border folk hero Gregorio Cortez:  the largest manhunt in U.S. history.\n",
    "\n",
    "### June 14, 1901 to June 22, 1901\n",
    "\n",
    "### based on lyrics from the Corrido de Gregorio Cortez (variant x english translation by Americo Paredes)\n",
    "\n",
    "#### project author Diane Lopez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import voila\n",
    "import geopandas as gpd\n",
    "\n",
    "import geograpy\n",
    "from geograpy import extraction\n",
    "from geograpy import places\n",
    "import re\n",
    "from geograpy.labels import Labels\n",
    "#from geograpy import geograpy-nltk\n",
    "\n",
    "import geopy\n",
    "from geopy.geocoders import Nominatim\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import shapely\n",
    "from shapely.geometry import Point\n",
    "\n",
    "import contextily as ctx\n",
    "import matplotlib.pyplot as plt #to make sure there are no errors when plotting a graph\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "#from mordecai import Geoparser\n",
    "import nltk\n",
    "\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "#from spacy.lang.en import English\n",
    "#from spacy.lang.es import Spanish\n",
    "#from spacy.pipeline import EntityRuler\n",
    "#from spacy.tokens import Doc\n",
    "#from spacy.training import Example\n",
    "#from spacy.language import Language\n",
    "\n",
    "import json\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Karnes', 'Gonzales', 'Belmont', 'Laredo', 'Encinal', 'Tell']\n"
     ]
    }
   ],
   "source": [
    "text = \"corrido corpus\\ElCorridodeGregorioCortez_X.txt\"\n",
    "with open(text, 'r', encoding='utf-8') as c:\n",
    "    text = c.read()\n",
    "    \n",
    "def clean_text(text):\n",
    "    cleaned= re.sub(r'[\":;,.“”]', \"\", text)\n",
    "    return(cleaned)\n",
    "text = clean_text(text)\n",
    "#print(text)\n",
    "\n",
    "\n",
    "TxGPE=[]\n",
    "nlp = spacy.load(\"tx_trained_ner\")\n",
    "doc =nlp(text) \n",
    "#print(doc)\n",
    "for ent in doc.ents:\n",
    "    #print(ent.text, ent.label_)\n",
    "    if ent.label_ == \"GPE\":\n",
    "        TxGPE.append(ent.text)\n",
    "print(TxGPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Karnes', 18, 24, 'GPE'), ('Gonzales', 1051, 1059, 'GPE'), ('Belmont', 1140, 1147, 'GPE'), ('Laredo', 1550, 1556, 'GPE'), ('Encinal', 1864, 1871, 'GPE'), ('Tell', 2135, 2139, 'GPE')]\n",
      "['Karnes', 'Gonzales', 'Belmont', 'Laredo', 'Encinal', 'Tell']\n"
     ]
    }
   ],
   "source": [
    "ents = [(e.text, e.start_char, e.end_char, e.label_)for e in doc.ents]\n",
    "print(ents)\n",
    "\n",
    "ents = [(e.text)for e in doc.ents]\n",
    "print(ents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Karnes Gonzales Belmont Laredo Encinal Tell\n"
     ]
    }
   ],
   "source": [
    "TxGPEStr = ' '.join([str(elem) for elem in TxGPE])\n",
    "print(TxGPEStr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><!DOCTYPE html>\n",
       "<html lang=\"en\">\n",
       "    <head>\n",
       "        <title>displaCy</title>\n",
       "    </head>\n",
       "\n",
       "    <body style=\"font-size: 16px; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol'; padding: 4rem 2rem; direction: ltr\">\n",
       "<figure style=\"margin-bottom: 6rem\">\n",
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">In the country of \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Karnes\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " </br>Look what has happened </br>The Major Sheriff died</br>Leaving Román badly wounded</br></br>It must have been two in the </br>afternoon</br>When people arrived</br>They said to one another</br>It is not known who killed him</br></br>They went around asking questions</br>About half an hour afterward </br>They found that the wrongdoer</br>Had been Gregorio Cortez</br></br>Now they have outlawed Cortez</br>Throughout the whole state</br>Let him be taken dead or alive </br>He has killed several men</br></br>They said Gregorio Cortez </br>With his pistol in his hand</br>I don’t regret that I killed him </br>I regret my brother’s death</br></br>Then said Gregorio Cortez </br>And his soul was all aflame </br>I don’t regret that I killed him</br>A man must defend himself</br></br>The Americans were coming </br>They were whiter than a dove </br>From the fear that they had </br>Of Cortez and of his pistol </br></br>Then the Americans said </br>Then they said fearfully</br>Come let us follow the trail</br>The wrongdoer is Cortez</br></br>They set the bloodhounds on him </br>So they could follow his trail </br>But trying to overtake  Cortez</br>Was like following a star </br></br>He struck out for \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Gonzales\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       "</br>Without showing any fear</br>Follow me cowardly rangers </br>I am Gregorio Cortez</br></br>From \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Belmont\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " he went to the </br>ranch  </br>They succeeded in surrounding </br>him </br>Quite a few more than three hundred </br>But there he jumped their corral </br></br>When he jumped their corral </br>According to what we hear</br>They got into a gunfight</br>And he killed them another sheriff </br></br>Then said Gregorio Cortez </br>With his pistol in his hand </br>Don’t run you cowardly rangers </br>From just one Mexican</br></br>Gregorio Cortez went out </br>He went towards \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Laredo\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       "</br>They decided not to follow </br>Because they were afraid of him</br></br>Then said Gregorio Cortez </br>What is the use of your scheming?</br>You cannot catch me</br>Even with those bloodhounds</br></br>Then the Americans said </br>If we catch you with him what </br>shall we do?</br>If we fight him man to man </br>Very few of us will return</br></br>Over by El \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Encinal\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " </br>According to what we hear </br>They made him a corral </br>And he killed them another sheriff </br></br>Then said Gregorio Cortez </br>Shooting out a lot of bullets</br>I have weathered thunderstorms</br>This little mist doesn’t bother me</br></br>Now he has met a Mexican</br>He says to him haughtily</br>\n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Tell\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " me the news</br>I am Gregorio Cortez</br></br>It is said that because of me </br>Many people have been killed</br>I will surrender now</br>Because such things are not right</br></br>Cortez says to Jesús</br>At last you are going to see it</br>Go tell the rangers</br>To come and arrest me</br></br>All the rangers were coming </br>Coming so fast they even flew </br>For they wanted to get </br>The thousand dollars they were </br>offered </br></br>When they surrounded the house </br>Cortez suddenly appeared before</br>\tthem </br>You will take me if I’m willing </br>But not any other way</br></br>Then the Major Sheriff said </br>As if he was going to cry </br>Cortez hand over your weapons</br>We are not going to kill</br></br>Then said Gregorio Cortez</br>Shouting to them in a loud voice</br>I won’t surrender my arms</br>Until I am in a cell</br></br>Then said Gregorio Cortez</br>He said in his godly voice </br>I won’t surrender my arms</br>Until I’m inside a jail</br></br>Now they have taken Cortez</br>Now matters are at an end </br>His poor family</br>Are suffering in their hearts</br></br>Now with this I say farewell </br>In the shade of a cypress tree</br>This the end of the singing </br>Of the ballad of Cortez</div>\n",
       "</figure>\n",
       "</body>\n",
       "</html></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "html =displacy.render(doc, style ='ent', jupyter=True, page=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {}
      }
     }
    }
   },
   "source": [
    "Geoparsing: Finding places from the corrido lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {}
      }
     }
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m LOC \u001b[39m=\u001b[39m geograpy\u001b[39m.\u001b[39mextraction\u001b[39m.\u001b[39mExtractor(text\u001b[39m=\u001b[39mdoc)\n\u001b[1;32m----> 3\u001b[0m LOC\u001b[39m.\u001b[39;49mfind_entities(labels\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mGPE\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\dmlpz\\anaconda3\\envs\\Greg\\lib\\site-packages\\geograpy\\extraction.py:82\u001b[0m, in \u001b[0;36mExtractor.find_entities\u001b[1;34m(self, labels)\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[0;32m     72\u001b[0m \u001b[39mFind entities with the given labels set self.places and returns it\u001b[39;00m\n\u001b[0;32m     73\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[39m        List of places\u001b[39;00m\n\u001b[0;32m     79\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[0;32m     80\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_text()\n\u001b[1;32m---> 82\u001b[0m text \u001b[39m=\u001b[39m nltk\u001b[39m.\u001b[39;49mword_tokenize(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtext)\n\u001b[0;32m     83\u001b[0m nes \u001b[39m=\u001b[39m nltk\u001b[39m.\u001b[39mne_chunk(nltk\u001b[39m.\u001b[39mpos_tag(text))\n\u001b[0;32m     85\u001b[0m \u001b[39mfor\u001b[39;00m ne \u001b[39min\u001b[39;00m nes:\n",
      "File \u001b[1;32mc:\\Users\\dmlpz\\anaconda3\\envs\\Greg\\lib\\site-packages\\nltk\\tokenize\\__init__.py:129\u001b[0m, in \u001b[0;36mword_tokenize\u001b[1;34m(text, language, preserve_line)\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mword_tokenize\u001b[39m(text, language\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39menglish\u001b[39m\u001b[39m\"\u001b[39m, preserve_line\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m    115\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[39m    Return a tokenized copy of *text*,\u001b[39;00m\n\u001b[0;32m    117\u001b[0m \u001b[39m    using NLTK's recommended word tokenizer\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[39m    :type preserve_line: bool\u001b[39;00m\n\u001b[0;32m    128\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 129\u001b[0m     sentences \u001b[39m=\u001b[39m [text] \u001b[39mif\u001b[39;00m preserve_line \u001b[39melse\u001b[39;00m sent_tokenize(text, language)\n\u001b[0;32m    130\u001b[0m     \u001b[39mreturn\u001b[39;00m [\n\u001b[0;32m    131\u001b[0m         token \u001b[39mfor\u001b[39;00m sent \u001b[39min\u001b[39;00m sentences \u001b[39mfor\u001b[39;00m token \u001b[39min\u001b[39;00m _treebank_word_tokenizer\u001b[39m.\u001b[39mtokenize(sent)\n\u001b[0;32m    132\u001b[0m     ]\n",
      "File \u001b[1;32mc:\\Users\\dmlpz\\anaconda3\\envs\\Greg\\lib\\site-packages\\nltk\\tokenize\\__init__.py:107\u001b[0m, in \u001b[0;36msent_tokenize\u001b[1;34m(text, language)\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     98\u001b[0m \u001b[39mReturn a sentence-tokenized copy of *text*,\u001b[39;00m\n\u001b[0;32m     99\u001b[0m \u001b[39musing NLTK's recommended sentence tokenizer\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[39m:param language: the model name in the Punkt corpus\u001b[39;00m\n\u001b[0;32m    105\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    106\u001b[0m tokenizer \u001b[39m=\u001b[39m load(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtokenizers/punkt/\u001b[39m\u001b[39m{\u001b[39;00mlanguage\u001b[39m}\u001b[39;00m\u001b[39m.pickle\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 107\u001b[0m \u001b[39mreturn\u001b[39;00m tokenizer\u001b[39m.\u001b[39;49mtokenize(text)\n",
      "File \u001b[1;32mc:\\Users\\dmlpz\\anaconda3\\envs\\Greg\\lib\\site-packages\\nltk\\tokenize\\punkt.py:1276\u001b[0m, in \u001b[0;36mPunktSentenceTokenizer.tokenize\u001b[1;34m(self, text, realign_boundaries)\u001b[0m\n\u001b[0;32m   1272\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtokenize\u001b[39m(\u001b[39mself\u001b[39m, text, realign_boundaries\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m   1273\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1274\u001b[0m \u001b[39m    Given a text, returns a list of the sentences in that text.\u001b[39;00m\n\u001b[0;32m   1275\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1276\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msentences_from_text(text, realign_boundaries))\n",
      "File \u001b[1;32mc:\\Users\\dmlpz\\anaconda3\\envs\\Greg\\lib\\site-packages\\nltk\\tokenize\\punkt.py:1332\u001b[0m, in \u001b[0;36mPunktSentenceTokenizer.sentences_from_text\u001b[1;34m(self, text, realign_boundaries)\u001b[0m\n\u001b[0;32m   1325\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msentences_from_text\u001b[39m(\u001b[39mself\u001b[39m, text, realign_boundaries\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m   1326\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1327\u001b[0m \u001b[39m    Given a text, generates the sentences in that text by only\u001b[39;00m\n\u001b[0;32m   1328\u001b[0m \u001b[39m    testing candidate sentence breaks. If realign_boundaries is\u001b[39;00m\n\u001b[0;32m   1329\u001b[0m \u001b[39m    True, includes in the sentence closing punctuation that\u001b[39;00m\n\u001b[0;32m   1330\u001b[0m \u001b[39m    follows the period.\u001b[39;00m\n\u001b[0;32m   1331\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1332\u001b[0m     \u001b[39mreturn\u001b[39;00m [text[s:e] \u001b[39mfor\u001b[39;00m s, e \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mspan_tokenize(text, realign_boundaries)]\n",
      "File \u001b[1;32mc:\\Users\\dmlpz\\anaconda3\\envs\\Greg\\lib\\site-packages\\nltk\\tokenize\\punkt.py:1332\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1325\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msentences_from_text\u001b[39m(\u001b[39mself\u001b[39m, text, realign_boundaries\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m   1326\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1327\u001b[0m \u001b[39m    Given a text, generates the sentences in that text by only\u001b[39;00m\n\u001b[0;32m   1328\u001b[0m \u001b[39m    testing candidate sentence breaks. If realign_boundaries is\u001b[39;00m\n\u001b[0;32m   1329\u001b[0m \u001b[39m    True, includes in the sentence closing punctuation that\u001b[39;00m\n\u001b[0;32m   1330\u001b[0m \u001b[39m    follows the period.\u001b[39;00m\n\u001b[0;32m   1331\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1332\u001b[0m     \u001b[39mreturn\u001b[39;00m [text[s:e] \u001b[39mfor\u001b[39;00m s, e \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mspan_tokenize(text, realign_boundaries)]\n",
      "File \u001b[1;32mc:\\Users\\dmlpz\\anaconda3\\envs\\Greg\\lib\\site-packages\\nltk\\tokenize\\punkt.py:1322\u001b[0m, in \u001b[0;36mPunktSentenceTokenizer.span_tokenize\u001b[1;34m(self, text, realign_boundaries)\u001b[0m\n\u001b[0;32m   1320\u001b[0m \u001b[39mif\u001b[39;00m realign_boundaries:\n\u001b[0;32m   1321\u001b[0m     slices \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_realign_boundaries(text, slices)\n\u001b[1;32m-> 1322\u001b[0m \u001b[39mfor\u001b[39;00m sentence \u001b[39min\u001b[39;00m slices:\n\u001b[0;32m   1323\u001b[0m     \u001b[39myield\u001b[39;00m (sentence\u001b[39m.\u001b[39mstart, sentence\u001b[39m.\u001b[39mstop)\n",
      "File \u001b[1;32mc:\\Users\\dmlpz\\anaconda3\\envs\\Greg\\lib\\site-packages\\nltk\\tokenize\\punkt.py:1421\u001b[0m, in \u001b[0;36mPunktSentenceTokenizer._realign_boundaries\u001b[1;34m(self, text, slices)\u001b[0m\n\u001b[0;32m   1408\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1409\u001b[0m \u001b[39mAttempts to realign punctuation that falls after the period but\u001b[39;00m\n\u001b[0;32m   1410\u001b[0m \u001b[39mshould otherwise be included in the same sentence.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1418\u001b[0m \u001b[39m    [\"(Sent1.)\", \"Sent2.\"].\u001b[39;00m\n\u001b[0;32m   1419\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1420\u001b[0m realign \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m-> 1421\u001b[0m \u001b[39mfor\u001b[39;00m sentence1, sentence2 \u001b[39min\u001b[39;00m _pair_iter(slices):\n\u001b[0;32m   1422\u001b[0m     sentence1 \u001b[39m=\u001b[39m \u001b[39mslice\u001b[39m(sentence1\u001b[39m.\u001b[39mstart \u001b[39m+\u001b[39m realign, sentence1\u001b[39m.\u001b[39mstop)\n\u001b[0;32m   1423\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m sentence2:\n",
      "File \u001b[1;32mc:\\Users\\dmlpz\\anaconda3\\envs\\Greg\\lib\\site-packages\\nltk\\tokenize\\punkt.py:318\u001b[0m, in \u001b[0;36m_pair_iter\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m    316\u001b[0m iterator \u001b[39m=\u001b[39m \u001b[39miter\u001b[39m(iterator)\n\u001b[0;32m    317\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 318\u001b[0m     prev \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(iterator)\n\u001b[0;32m    319\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n\u001b[0;32m    320\u001b[0m     \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\dmlpz\\anaconda3\\envs\\Greg\\lib\\site-packages\\nltk\\tokenize\\punkt.py:1395\u001b[0m, in \u001b[0;36mPunktSentenceTokenizer._slices_from_text\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m   1393\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_slices_from_text\u001b[39m(\u001b[39mself\u001b[39m, text):\n\u001b[0;32m   1394\u001b[0m     last_break \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m-> 1395\u001b[0m     \u001b[39mfor\u001b[39;00m match, context \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_match_potential_end_contexts(text):\n\u001b[0;32m   1396\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtext_contains_sentbreak(context):\n\u001b[0;32m   1397\u001b[0m             \u001b[39myield\u001b[39;00m \u001b[39mslice\u001b[39m(last_break, match\u001b[39m.\u001b[39mend())\n",
      "File \u001b[1;32mc:\\Users\\dmlpz\\anaconda3\\envs\\Greg\\lib\\site-packages\\nltk\\tokenize\\punkt.py:1375\u001b[0m, in \u001b[0;36mPunktSentenceTokenizer._match_potential_end_contexts\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m   1373\u001b[0m before_words \u001b[39m=\u001b[39m {}\n\u001b[0;32m   1374\u001b[0m matches \u001b[39m=\u001b[39m []\n\u001b[1;32m-> 1375\u001b[0m \u001b[39mfor\u001b[39;00m match \u001b[39min\u001b[39;00m \u001b[39mreversed\u001b[39m(\u001b[39mlist\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_lang_vars\u001b[39m.\u001b[39;49mperiod_context_re()\u001b[39m.\u001b[39;49mfinditer(text))):\n\u001b[0;32m   1376\u001b[0m     \u001b[39m# Ignore matches that have already been captured by matches to the right of this match\u001b[39;00m\n\u001b[0;32m   1377\u001b[0m     \u001b[39mif\u001b[39;00m matches \u001b[39mand\u001b[39;00m match\u001b[39m.\u001b[39mend() \u001b[39m>\u001b[39m before_start:\n\u001b[0;32m   1378\u001b[0m         \u001b[39mcontinue\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: expected string or bytes-like object"
     ]
    }
   ],
   "source": [
    "LOC = geograpy.extraction.Extractor(text=doc)\n",
    "\n",
    "LOC.find_entities(labels='GPE')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "pc = places.PlaceContext(TxGPEStr)\n",
    "\n",
    "pc.set_countries()\n",
    "print (pc.countries) #['United States']\n",
    "\n",
    "pc.set_regions()\n",
    "print(pc.regions) #['Texas'])\n",
    "\n",
    "pc.set_cities()\n",
    "print(pc.cities) #['Brownsville'])\n",
    "\n",
    "print(pc.address_strings) #['Brownsville','Texas, United States'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {}
      }
     }
    }
   },
   "source": [
    "Laredo, Tejas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "geolocator = Nominatim(user_agent=\"CorridosMap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "laredo=pc.cities[0]\n",
    "print (laredo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {}
      }
     }
    }
   },
   "source": [
    "need to know the country code https://en.wikipedia.org/wiki/ISO_3166-1_alpha-2#Current_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "laredo_info = geolocator.geocode(laredo)\n",
    "laredo_lat = (laredo_info.latitude) \n",
    "laredo_long= (laredo_info.longitude)\n",
    "print(laredo_info)\n",
    "print(laredo_long,',', laredo_lat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {}
      }
     }
    }
   },
   "source": [
    "Belmont, Tejas/Texas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "belmont='Belmont, Gonzales County,Texas'\n",
    "#belmont=pc.cities[1]\n",
    "belmont_info=geolocator.geocode(belmont)\n",
    "belmont_lat = (belmont_info.latitude)\n",
    "belmont_long= (belmont_info.longitude)\n",
    "print(belmont_info)\n",
    "print(belmont_long,',', belmont_lat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {}
      }
     }
    }
   },
   "source": [
    "Gonzales, Tejas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#gonzales='Gonzales,Texas'\n",
    "gonzales=pc.cities[2]\n",
    "gonzales_info=geolocator.geocode(gonzales)\n",
    "gonzales_lat = (gonzales_info.latitude) \n",
    "gonzales_long =(gonzales_info.longitude)\n",
    "#gonzales=gonzales_info, gonzales_coordinates\n",
    "print(gonzales_lat, ',', gonzales_long)\n",
    "print(gonzales_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {}
      }
     }
    }
   },
   "source": [
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "greg = pd.DataFrame({'Place':[gonzales, 'Belmont', laredo], 'State': ['Texas', 'Texas', 'Texas'], \n",
    "'Latitude':[gonzales_lat, belmont_lat, laredo_lat], 'Longitude': [gonzales_long, belmont_long, laredo_long]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {}
      }
     }
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "greg.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {}
      }
     }
    }
   },
   "source": [
    "Setting Geometry- https://geopandas.org/en/stable/docs/reference/api/geopandas.GeoDataFrame.set_geometry.html#\n",
    "\n",
    "Creating a GeoDataFrame from a DataFrame with coordinates https://geopandas.org/en/stable/gallery/create_geopandas_from_pandas.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "greg_gpd = gpd.GeoDataFrame(\n",
    "    greg, geometry=gpd.points_from_xy(greg.Longitude, greg.Latitude),  crs=\"EPSG:4326\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {}
      }
     }
    }
   },
   "source": [
    "figure out later shapely 2.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "print(greg_gpd.head())\n",
    "#greg_gpd.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "#greg_gpd_basemap, greg_gpd_extent = ctx.bounds2img(*greg_gpd.total_bounds, zoom=10,   \n",
    "                                            #source=ctx.providers.OpenStreetMap.Mapnik )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {}
      }
     }
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "px.set_mapbox_access_token(open(\"mapboxtoken\").read())\n",
    "\n",
    "fig = px.scatter_mapbox(greg_gpd, \n",
    "                        color='Place',\n",
    "                        animation_group='Place',\n",
    "                        animation_frame=['Gonzales', 'Belmont', 'Laredo'],\n",
    "                        lat=greg_gpd.geometry.y, \n",
    "                        lon=greg_gpd.geometry.x, \n",
    "                        hover_name='Place',\n",
    "                        size='Latitude',\n",
    "                        zoom=5,\n",
    "                        width=500,\n",
    "                        height=500,\n",
    "                        title=(\"Gregorio Cortez on the run (June 14 to 22, 1901)\"),\n",
    "                        mapbox_style='carto-positron'                               \n",
    "                        )\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "greg_gpd.to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "greg_gpd.to_file(r\"C:\\Users\\dmlpz\\Corridos\", driver=\"GeoJSON\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.write_html(\"../corridos/gregmap.html\")"
   ]
  }
 ],
 "metadata": {
  "extensions": {
   "jupyter_dashboards": {
    "activeView": "grid_default",
    "version": 1,
    "views": {
     "grid_default": {
      "cellMargin": 10,
      "defaultCellHeight": 20,
      "maxColumns": 12,
      "name": "grid",
      "type": "grid"
     },
     "report_default": {
      "name": "report",
      "type": "report"
     }
    }
   }
  },
  "kernelspec": {
   "display_name": "Greg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "c33b8046986a03aa44ef4ea500a2630dcd79ff60fec54402ff1309c4dcbd3e63"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
