{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d06f4599",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.lang.en import English\n",
    "from spacy.lang.es import Spanish\n",
    "from spacy.pipeline import EntityRuler\n",
    "import json\n",
    "import random\n",
    "from spacy.tokens import Doc\n",
    "from spacy.training import Example\n",
    "from spacy.language import Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69a6ce7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.4.4\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "print(spacy.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3659aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#don't mess with the codeblock box\n",
    "#1 NER Spacy create training data\n",
    "import json \n",
    "\n",
    "def load_data(file):\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        #print(f)\n",
    "        return(json.load(f))\n",
    "    \n",
    "def save_data (file, data):\n",
    "    with open (file, \"w\", encoding='utf-8') as f:\n",
    "       data = json.dump(data, f, indent=4)\n",
    "       print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6167a678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Municipalities\n",
      "List of Unincorparated Communities\n",
      "List of Ghost Town\n"
     ]
    }
   ],
   "source": [
    "#dont mess with the codeblock box \n",
    "# 1 NER Spacy create training data\n",
    "\n",
    "def create_training_data(file, type):\n",
    "    #print(type)\n",
    "    #print(file)\n",
    "    data = load_data(file)\n",
    "    #print(data)\n",
    "    patterns=[]\n",
    "    for key, value in data.items():\n",
    "        print(key)\n",
    "        if key == \"List of Municipalities\":\n",
    "            for obj in value: #muni loop\n",
    "                #print(obj.get(\"Municipality\"))\n",
    "                pattern = {\n",
    "                    \"label\":type,\n",
    "                    \"pattern\": obj.get(\"Municipality\")\n",
    "                    }\n",
    "                patterns.append(pattern) # end of muni loop\n",
    "            for obj in value: #primary county loop \n",
    "                #if any(d.get(\"Primary County\") == \"Gonzales\" for d in value): \n",
    "                    #print(\"found in Municipality\") \n",
    "                if not any(d.get(\"Municipality\") == obj.get(\"Primary County\") for d in value):\n",
    "                    #print('not found in Manicipality')\n",
    "                    pattern = {\n",
    "                        \"label\":type,\n",
    "                        \"pattern\": obj.get(\"Primary County\")\n",
    "                        }\n",
    "                    patterns.append(pattern)           \n",
    "\n",
    "        if key == \"List of Unincorparated Communities\":\n",
    "            for obj in value: #muni loop\n",
    "                #print(obj.get(\"Municipality\"))\n",
    "                pattern = {\n",
    "                    \"label\":type,\n",
    "                    \"pattern\": obj.get(\"Community Name\")\n",
    "                    }\n",
    "                patterns.append(pattern) # end of community name loop\n",
    "            for obj in value: #county loop \n",
    "                if not any(d.get(\"Community Name\") == obj.get(\"County\") for d in value):\n",
    "                    pattern = {\n",
    "                        \"label\":type,\n",
    "                        \"pattern\": obj.get(\"County\")\n",
    "                        }\n",
    "                    patterns.append(pattern)                 \n",
    "\n",
    "        if key == \"List of Ghost Town\":\n",
    "            for obj in value: #ghost town loop\n",
    "                #print(obj.get(\"Municipality\"))\n",
    "                pattern = {\n",
    "                    \"label\":type,\n",
    "                    \"pattern\": obj.get(\"Name\")\n",
    "                    }\n",
    "                patterns.append(pattern) # end of muni loop\n",
    "            for obj in value: #county loop \n",
    "                if not any(d.get(\"Name\") == obj.get(\"County\") for d in value):\n",
    "                    pattern = {\n",
    "                        \"label\":type,\n",
    "                        \"pattern\": obj.get(\"County\")\n",
    "                        }\n",
    "                    patterns.append(pattern)\n",
    "\n",
    "        #for obj in value: # unicorpated communities loop\n",
    "                #if any(d.get(\"Primary County\")=='Karnes' for d in value): \n",
    "                    #print(\"found in Primary County\")\n",
    "        \n",
    "            #print(pattern)\n",
    "            #print(patterns)\n",
    "\n",
    "    return(patterns)\n",
    "patterns = create_training_data('../Corridos/data/TexasNER_GPE_master.json', 'GPE')\n",
    "#print(patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8cb1fa40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['In the country of Karnes  Look what has happened  The Major Sheriff died Leaving Román badly wounded', {'entities': [(18, 24, 'GPE')]}]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "['He struck out for Gonzales Without showing any fear Follow me cowardly rangers  I am Gregorio Cortez', {'entities': [(18, 26, 'GPE')]}]\n",
      "['From Belmont he went to the  ranch   They succeeded in surrounding  him  Quite a few more than three hundred  But there he jumped their corral', {'entities': [(5, 12, 'GPE')]}]\n",
      "[]\n",
      "[]\n",
      "['Gregorio Cortez went out  He went towards Laredo They decided not to follow  Because they were afraid of him', {'entities': [(42, 48, 'GPE')]}]\n",
      "[]\n",
      "[]\n",
      "['Over by El Encinal  According to what we hear  They made him a corral  And he killed them another sheriff', {'entities': [(11, 18, 'GPE')]}]\n",
      "[]\n",
      "['Now he has met a Mexican He says to him haughtily Tell me the news I am Gregorio Cortez', {'entities': [(50, 54, 'GPE')]}]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# start run here iff NEEDED. \n",
    "# don't mess with this codeblock box\n",
    "#TX NER TRAINING SET \n",
    "#from 2 NER Spacy- Creating NER training data set Notebook\n",
    "\n",
    "def generate_rules(patterns):\n",
    "    nlp = English()\n",
    "    #ruler = EntityRuler(nlp)\n",
    "    ruler = nlp.add_pipe('entity_ruler', config={\"validate\": True})\n",
    "    ruler.add_patterns(patterns) \n",
    "    nlp.to_disk(\"tx_trained_ner\")\n",
    "\n",
    "def test_model(model, text):\n",
    "    doc = nlp(text)\n",
    "    results = []\n",
    "    entities = []\n",
    "    for ent in doc.ents:\n",
    "        entities.append((ent.start_char, ent.end_char, ent.label_))\n",
    "    if len(entities) >0: #if entity has been found move entity to results and entity list\n",
    "        results = [text, {\"entities\": entities}]\n",
    "        #print(results)\n",
    "    return (results)\n",
    "\n",
    "#patterns = create_training_data('../Corridos/data/TexasNER_GPE_master.json', 'GPE')\n",
    "generate_rules(patterns)\n",
    "#print(patterns)\n",
    "\n",
    "#how spacy wants to see read the data#\n",
    "#TRAIN_DATA = [(text, {\"entities\": [(start, end, label)]})]#\n",
    "\n",
    "nlp = spacy.load(\"tx_trained_ner\")\n",
    "TRAIN_DATA= []\n",
    "\n",
    "with open (\"../Corridos/corrido corpus/ElCorridodeGregorioCortez_X.txt\", \"r\", encoding='utf-8')as f:\n",
    "    text = f.read()\n",
    "    #print(text)\n",
    "    segments = text.split(\"\\n\\n\")[0:]\n",
    "    #cleaning up the lyric text. making it easier to read for the program\n",
    "    for segment in segments:\n",
    "        segment = segment.strip() #might not need this code line \n",
    "        segment = segment.replace(\"\\n\", \" \")# might not need this code line\n",
    "        #print(segment)\n",
    "        punc = '[\":;,“.”[@_!$%^&*()<>?/\\|}{~:]#]'\n",
    "        for ele in segment:\n",
    "            if ele in punc:\n",
    "                segment = segment.replace(ele, \"\")\n",
    "\n",
    "        #print(segment)\n",
    "\n",
    "        results = test_model(nlp, segment)\n",
    "        if results != []: #it found something and return it\n",
    "            TRAIN_DATA.append(results)\n",
    "        print(results)\n",
    "\n",
    "#print(TRAIN_DATA)\n",
    "save_data(\"../Corridos/data/Tx_NER_GPE_training_data.json\", TRAIN_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6e21314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(18, 24, 'GPE')]\n",
      "[(18, 26, 'GPE')]\n",
      "[(5, 12, 'GPE')]\n",
      "[(42, 48, 'GPE')]\n",
      "[(11, 18, 'GPE')]\n",
      "[(50, 54, 'GPE')]\n",
      "Starting iteration 0\n",
      "{'ner': 90.84429782629013}\n",
      "Starting iteration 1\n",
      "{'ner': 33.199651723727584}\n",
      "Starting iteration 2\n",
      "{'ner': 11.526059872021676}\n",
      "Starting iteration 3\n",
      "{'ner': 10.16693946277229}\n",
      "Starting iteration 4\n",
      "{'ner': 6.787411320240153}\n",
      "Starting iteration 5\n",
      "{'ner': 4.228821545744196}\n",
      "Starting iteration 6\n",
      "{'ner': 2.307036544627187}\n",
      "Starting iteration 7\n",
      "{'ner': 0.30418643871934636}\n",
      "Starting iteration 8\n",
      "{'ner': 0.001348462090086763}\n",
      "Starting iteration 9\n",
      "{'ner': 0.00010607708487035228}\n",
      "Starting iteration 10\n",
      "{'ner': 3.0935832119201046e-05}\n",
      "Starting iteration 11\n",
      "{'ner': 1.943471083366505e-06}\n",
      "Starting iteration 12\n",
      "{'ner': 1.6519375958004647e-06}\n",
      "Starting iteration 13\n",
      "{'ner': 6.0417582056836914e-09}\n",
      "Starting iteration 14\n",
      "{'ner': 4.672293260947626e-05}\n",
      "Starting iteration 15\n",
      "{'ner': 5.810358069127598e-07}\n",
      "Starting iteration 16\n",
      "{'ner': 5.416693719742019e-07}\n",
      "Starting iteration 17\n",
      "{'ner': 2.755641354782398e-06}\n",
      "Starting iteration 18\n",
      "{'ner': 9.132383470760365e-08}\n",
      "Starting iteration 19\n",
      "{'ner': 1.7204880436438829e-09}\n",
      "Starting iteration 20\n",
      "{'ner': 3.0703401881107765e-08}\n",
      "Starting iteration 21\n",
      "{'ner': 9.27933949210547e-08}\n",
      "Starting iteration 22\n",
      "{'ner': 7.039249618675636e-10}\n",
      "Starting iteration 23\n",
      "{'ner': 1.3350147533212703e-05}\n",
      "Starting iteration 24\n",
      "{'ner': 1.6188091422996655e-09}\n",
      "Starting iteration 25\n",
      "{'ner': 1.590842430187021e-09}\n",
      "Starting iteration 26\n",
      "{'ner': 4.5781074311520927e-10}\n",
      "Starting iteration 27\n",
      "{'ner': 2.8477024142910296e-10}\n",
      "Starting iteration 28\n",
      "{'ner': 1.8437734971749373e-10}\n",
      "Starting iteration 29\n",
      "{'ner': 7.553002981891747e-10}\n"
     ]
    }
   ],
   "source": [
    "def train_spacy(data, iterations): #passing training data/set and the number/generation of the training process. 30 is good. long time!!!!\n",
    "    #print(data)\n",
    "    TRAIN_DATA = data\n",
    "    #print(TRAIN_DATA)\n",
    "    nlp = spacy.blank(\"en\")\n",
    "    #print(nlp)\n",
    "    if \"ner\" not in nlp.pipe_names:\n",
    "        ner = nlp.create_pipe(\"ner\") #if there is no ner in the pipe, create a pipe\n",
    "        nlp.add_pipe(\"ner\", last=True)\n",
    "    \n",
    "    for _, annotations in TRAIN_DATA: #add labels\n",
    "        print(annotations.get(\"entities\"))\n",
    "        for ent in annotations.get(\"entities\"):\n",
    "            ner.add_label(ent[2]) # i'm only working with one label 'GPE' if more increase i believe double check\n",
    "    \n",
    "    other_pipes = [pipe for pipe in nlp.pipe_names if pipe != \"ner\"]  \n",
    "    with nlp.disable_pipes(*other_pipes): #won't mess up other pipes\n",
    "        optimizer = nlp.begin_training()\n",
    "        for itn in range(iterations): # adjust the funtion not the items inside. arg of interations 30 is good\n",
    "            print(\"Starting iteration \"+ str(itn)) #where I am at in the interations process\n",
    "            random.shuffle(TRAIN_DATA) #shuffle helps the program to learn not memorize order. \n",
    "            losses = {}\n",
    "            for text, annotations in TRAIN_DATA:\n",
    "                doc = nlp.make_doc(text)\n",
    "                example = Example.from_dict(doc, annotations) #fix found here for ValueError: [E973] Unexpected type for NER data https://github.com/explosion/spaCy/issues/7038\n",
    "                nlp.update([example], drop = 0.2, sgd= optimizer, losses=losses)            \n",
    "            print(losses)  \n",
    "    \n",
    "    return(nlp) #model return\n",
    "\n",
    "#TRAIN_DATA = load_data(\"../Corridos/data/TxMunicipality_training_data.json\")\n",
    "#print(TRAIN_DATA)\n",
    "nlp = train_spacy(TRAIN_DATA, 30)\n",
    "nlp.to_disk(\"tx_ner_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a65b1e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "In the country of Karnes \n",
      "Look what has happened \n",
      "The Major Sheriff died\n",
      "Leaving Román badly wounded\n",
      "\n",
      "It must have been two in the \n",
      "afternoon\n",
      "When people arrived\n",
      "They said to one another\n",
      "It is not known who killed him\n",
      "\n",
      "They went around asking questions\n",
      "About half an hour afterward \n",
      "They found that the wrongdoer\n",
      "Had been Gregorio Cortez\n",
      "\n",
      "Now they have outlawed Cortez\n",
      "Throughout the whole state\n",
      "Let him be taken dead or alive \n",
      "He has killed several men\n",
      "\n",
      "They said Gregorio Cortez \n",
      "With his pistol in his hand\n",
      "I don’t regret that I killed him \n",
      "I regret my brother’s death\n",
      "\n",
      "Then said Gregorio Cortez \n",
      "And his soul was all aflame \n",
      "I don’t regret that I killed him\n",
      "A man must defend himself\n",
      "\n",
      "The Americans were coming \n",
      "They were whiter than a dove \n",
      "From the fear that they had \n",
      "Of Cortez and of his pistol \n",
      "\n",
      "Then the Americans said \n",
      "Then they said fearfully\n",
      "Come let us follow the trail\n",
      "The wrongdoer is Cortez\n",
      "\n",
      "They set the bloodhounds on him \n",
      "So they could follow his trail \n",
      "But trying to overtake  Cortez\n",
      "Was like following a star \n",
      "\n",
      "He struck out for Gonzales\n",
      "Without showing any fear\n",
      "Follow me cowardly rangers \n",
      "I am Gregorio Cortez\n",
      "\n",
      "From Belmont he went to the \n",
      "ranch  \n",
      "They succeeded in surrounding \n",
      "him \n",
      "Quite a few more than three hundred \n",
      "But there he jumped their corral \n",
      "\n",
      "When he jumped their corral \n",
      "According to what we hear\n",
      "They got into a gunfight\n",
      "And he killed them another sheriff \n",
      "\n",
      "Then said Gregorio Cortez \n",
      "With his pistol in his hand \n",
      "Don’t run you cowardly rangers \n",
      "From just one Mexican\n",
      "\n",
      "Gregorio Cortez went out \n",
      "He went towards Laredo\n",
      "They decided not to follow \n",
      "Because they were afraid of him\n",
      "\n",
      "Then said Gregorio Cortez \n",
      "What is the use of your scheming?\n",
      "You cannot catch me\n",
      "Even with those bloodhounds\n",
      "\n",
      "Then the Americans said \n",
      "If we catch you with him what \n",
      "shall we do?\n",
      "If we fight him man to man \n",
      "Very few of us will return\n",
      "\n",
      "Over by El Encinal \n",
      "According to what we hear \n",
      "They made him a corral \n",
      "And he killed them another sheriff \n",
      "\n",
      "Then said Gregorio Cortez \n",
      "Shooting out a lot of bullets\n",
      "I have weathered thunderstorms\n",
      "This little mist doesn’t bother me\n",
      "\n",
      "Now he has met a Mexican\n",
      "He says to him haughtily\n",
      "Tell me the news\n",
      "I am Gregorio Cortez\n",
      "\n",
      "It is said that because of me \n",
      "Many people have been killed\n",
      "I will surrender now\n",
      "Because such things are not right\n",
      "\n",
      "Cortez says to Jesús\n",
      "At last you are going to see it\n",
      "Go tell the rangers\n",
      "To come and arrest me\n",
      "\n",
      "All the rangers were coming \n",
      "Coming so fast they even flew \n",
      "For they wanted to get \n",
      "The thousand dollars they were \n",
      "offered \n",
      "\n",
      "When they surrounded the house \n",
      "Cortez suddenly appeared before\n",
      "\tthem \n",
      "You will take me if I’m willing \n",
      "But not any other way\n",
      "\n",
      "Then the Major Sheriff said \n",
      "As if he was going to cry \n",
      "Cortez hand over your weapons\n",
      "We are not going to kill\n",
      "\n",
      "Then said Gregorio Cortez\n",
      "Shouting to them in a loud voice\n",
      "I won’t surrender my arms\n",
      "Until I am in a cell\n",
      "\n",
      "Then said Gregorio Cortez\n",
      "He said in his godly voice \n",
      "I won’t surrender my arms\n",
      "Until I’m inside a jail\n",
      "\n",
      "Now they have taken Cortez\n",
      "Now matters are at an end \n",
      "His poor family\n",
      "Are suffering in their hearts\n",
      "\n",
      "Now with this I say farewell \n",
      "In the shade of a cypress tree\n",
      "This the end of the singing \n",
      "Of the ballad of Cortez\n",
      "['Karnes', 'Gonzales', 'Belmont', 'Laredo', 'Encinal', 'Tell', 'Until', 'Until', 'This']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'   \\nnlp = spacy.load(\"en_core_web_lg\") \\ndoc = nlp(test)\\nTxGPE=[]\\nfor ent in doc.ents:\\n    #print(ent.text, ent.label_)\\n    if ent.label_ == \"GPE\":\\n        TxGPE.append(ent.text)\\nprint(TxGPE)\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#time to test\n",
    "test= \"corrido corpus\\ElCorridodeGregorioCortez_X.txt\"\n",
    "with open(test, 'r', encoding='utf-8') as c:\n",
    "    test = c.read()\n",
    "\n",
    "\n",
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    cleaned= re.sub(r'[\":;,.“”]', \"\", text)\n",
    "    return(cleaned)\n",
    "test = clean_text(test)\n",
    "print(test)\n",
    "\n",
    "TxGPE=[]\n",
    "nlp = spacy.load(\"tx_ner_model\")\n",
    "doc =nlp(test) \n",
    "#print(doc)\n",
    "for ent in doc.ents:\n",
    "    #print(ent.text, ent.label_)\n",
    "    if ent.label_ == \"GPE\":\n",
    "        TxGPE.append(ent.text)\n",
    "print(TxGPE)\n",
    "'''   \n",
    "nlp = spacy.load(\"en_core_web_lg\") \n",
    "doc = nlp(test)\n",
    "TxGPE=[]\n",
    "for ent in doc.ents:\n",
    "    #print(ent.text, ent.label_)\n",
    "    if ent.label_ == \"GPE\":\n",
    "        TxGPE.append(ent.text)\n",
    "print(TxGPE)\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Greg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "c33b8046986a03aa44ef4ea500a2630dcd79ff60fec54402ff1309c4dcbd3e63"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
