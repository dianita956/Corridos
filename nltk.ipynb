{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLTK "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install nltk\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install vaderSentiment\n",
    "from vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# Initialize VADER so we can use it later\n",
    "sa = SentimentIntensityAnalyzer()\n",
    "\n",
    "import re\n",
    "\n",
    "#%pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip pandas\n",
    "import pandas as pd\n",
    "pd.options.display.max_colwidth = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in text file\n",
    "text = open(\"corrido corpus\\gregoriocortez_es_corrido.txt\", encoding=\"utf-8\").read()\n",
    "# Replace line breaks with spaces\n",
    "text = text.replace('\\n', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.sent_tokenize(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for number, sentence in enumerate(nltk.sent_tokenize(text)):\n",
    "    print(number, sentence)\n",
    " # Break text into sentences\n",
    "sentences = nltk.sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Break text into sentences\n",
    "sentences = nltk.sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make empty list\n",
    "sentence_scores = []\n",
    "# Get each sentence and sentence number, which is what enumerate does\n",
    "for number, sentence in enumerate(sentences):\n",
    "    # Use VADER to calculate sentiment\n",
    "    scores = sa.polarity_scores(sentence)\n",
    "    # Make dictionary and append it to the previously empty list\n",
    "    sentence_scores.append({'sentence': sentence, 'sentence_number': number+1, 'sentiment_score': scores['compound']})\n",
    "pd.DataFrame(sentence_scores)\n",
    " # Assign DataFrame to variable red_df\n",
    " # 10 most negative sentence\n",
    "greg_df = pd.DataFrame(sentence_scores)\n",
    "greg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by the column \"sentiment_score\" and slice for first 10 values\n",
    "# 10 negative sentence_scores\n",
    "greg_df.sort_values(by='sentiment_score')[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    " # 10 positive sentence_scores\n",
    " # Sort by the column \"sentiment_score,\" this time in descending order, and slice for first 10 values\n",
    "\n",
    "greg_df.sort_values(by='sentiment_score', ascending=False)[:10]\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make a sentiment plot\n",
    "greg_df['sentiment_score'].plot();\n",
    " \n",
    "ax = greg_df['sentiment_score'].plot(x='sentence_number', y='sentiment_score', kind='line',\n",
    "                        figsize=(10,5), rot=90, title='Sentiment in Gregorio Cortez Corrido')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install matplotlib\n",
    "import matplotlib.pyplot as plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot a horizontal line at 0\n",
    "plot.axhline(y=0, color='orange', linestyle='-');\n",
    " # Get averages for a rolling window, then plot\n",
    "greg_df.rolling(5)['sentiment_score'].mean().plot(x='sentence_number', y='sentiment_score', kind='line',\n",
    "                        figsize=(10,5), rot=90, title='Sentiment in \"Gregorio Cortez Corrido\"')\n",
    "\n",
    "# Plot a horizontal line at 0\n",
    "plot.axhline(y=0, color='orange', linestyle='-');\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word freqencies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from nltk.corpus.reader.plaintext import PlaintextCorpusReader\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exploring corpus\n",
    "path_corridos = os.getcwd()\n",
    "greg_file = 'gregoriocortez_es_corrido.txt'\n",
    "corpus = PlaintextCorpusReader( path_corridos, greg_file)\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a custom data/stop_words.csv if available\n",
    "# Otherwise, load the nltk stopwords list in English\n",
    "# Create an empty Python list to hold the stopwords\n",
    "stop_words = []\n",
    "# The filename of the custom data/stop_words.csv file\n",
    "stopwords_greg = 'corrido corpus\\gregoriocortez_es_corrido.txt'\n",
    "if os.path.exists(stopwords_greg):\n",
    "    #import csv\n",
    "    with open(stopwords_greg, 'r', encoding=\"utf-8\") as f:\n",
    "        stop_words = list(f)[0]\n",
    "    print('Custom stopwords list loaded from doc')\n",
    "else:\n",
    "    # Load the NLTK stopwords list\n",
    "    from nltk.corpus import stopwords\n",
    "    stop_words = stopwords.words('spanish')\n",
    "    print('NLTK stopwords list loaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stops = set(stopwords.words('spanish'))\n",
    "print(stops)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Geography\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install geograpy3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geograpy\n",
    "from geograpy import extraction\n",
    "places = extraction.Extractor(text= '''En el condado El Carmen miren lo que ha sucedido, murió el Cherife Mayor, quedando Román herido.\n",
    "Se anduvieron informando como media hora después supieropn que el malhechor era Gregorio Cortez.\n",
    "Ya insortaron a Cortez por toditito el estado, que vivo o muerto se aprehenda proque a various ha matado.\n",
    "Decía Gregorio Cortez con su pistola en la mano: No siento haberlo matado, lo que siento es a mi hermano.\n",
    "Decía Gregorio Cortez con su almu my encendid: No siento haberlo matado, la defensa es permitida.\n",
    "Venían los american mas blancos que una amapola, de miedo que le tenían a Cortez con su pistola.\n",
    "Decían los americanos, decían con timidez: Vamos a seguir la huella que el malhechor es Cortez.\n",
    "Soltaron los perros juanes pa'que siguieran la huella, pero alcanzar a Cortez.\n",
    "Tiró con rumbo a Gonzales sin ninguna timidez: Síganme, rinches cobardes, yo soy Gregorio Cortez.\n",
    "Se fue de Belmont al rancho, lo alcanzaron a rodear, poquitos más de trescientos, y allí les brincó el corral.\n",
    "Cuando les brincó el corral, según lo que aquí se dice, se agarraron a balazos, y les mató otro cherife.\n",
    "Decía Gregorio Cortez con su pistola en la mano: No corran, rinches cobardes, con un solo mexicano.\n",
    "Salió Gregorio Cortez, salió con rumbo a Laredo, no lo quisieron seguir porque le tuvieron miedo.\n",
    "Decía Gregorio Cortez: Pa' qué se velen de planes? No me pueden agarrar ni con esos perros juanes.\n",
    "Decían Los americanos: Si lo alcanzamos por derecho myu poquitos volveremos.\n",
    "Allá por El Encinal, según lo que aquí se dice, le formaron un corral y les mató otro cherife.\n",
    "Decía Gregorio Cortez echando muchos balazos: Me ha escapado de aquaceros, contimás de nublinazos.\n",
    "Ya se encontrá a un mexicano, le dice con altivez: Platícame qué hay de nuevo, yo soy Gregorio Cortez.\n",
    "Dicen que por culpa mía han matado mucha gente, pues ya me voy a entregar porque eso no es convieniente.\n",
    "Cortez le dice a Jesús: Oro sí lo vas a ver, anda diles los rinches que vengan a aprehender.\n",
    "Venían todos los rinches, venían que hasta volaban, porque se iban a ganer diez mil pesos que le daban.\n",
    "Cuando rodearon la case Cortez se les presentó: Por la buena sí me llevan proque de otro modo no.\n",
    "Decía el Cheride Mayor como queriendo llorar: Cortez, entrega tus armas, no te vamos a matar.\n",
    "Decía Gregorio Cortez, les gritaba en alta voz: Mis armas no las entrego hasta estar en calaboz.\n",
    "Decía Gregorio Cortez, decía en su voz divina: Mis armas no las entrgo hasta estar en bartolina.\n",
    "Ya agarron a Cortez, ya terminó la cuestion, la pobre de sui familia lo lleva en el corazón.\n",
    "Ya con esta me despido a la sombra de un ciprés, aquí se acaba el corrido de don Gregorio Cortez.''')\n",
    "\n",
    "places.find_geoEntities()\n",
    "\n",
    "print(places.places)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geograpy import places\n",
    "\n",
    "pc = places.PlaceContext(['Gonzales', 'Laredo', 'Belmont'])\n",
    "\n",
    "pc.set_countries()\n",
    "print (pc.countries) #['United States']\n",
    "\n",
    "pc.set_regions()\n",
    "print(pc.regions) #['Ohio'])\n",
    "\n",
    "pc.set_cities()\n",
    "print(pc.cities) #['Cleveland'])\n",
    "\n",
    "print(pc.address_strings) #['Cleveland, Ohio, United States'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install geopy\n",
    "from geopy.geocoders import Nominatim\n",
    "import time\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate a new Nominatim client\n",
    "geolocator = Nominatim(user_agent=\"CorridosMap\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Laredo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Laredo = \"Laredo, Texas\"\n",
    "Laredo_info = geolocator.geocode(Laredo)\n",
    "Laredo_coordinates = (Laredo_info.latitude, Laredo_info.longitude)\n",
    "pprint(Laredo_info)\n",
    "pprint(Laredo_coordinates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Belmont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Belmont = \"Belmont, Texas\"\n",
    "Belmont_info = geolocator.geocode(Belmont)\n",
    "Belmont_coordinates = (Belmont_info.latitude, Belmont_info.longitude)\n",
    "pprint(Belmont_info)\n",
    "pprint(Belmont_coordinates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gonzales, Texas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gonzales = \"Gonzales, Texas\"\n",
    "Gonzales_info = geolocator.geocode(Gonzales)\n",
    "Gonzales_coordinates = (Gonzales_info.latitude, Gonzales_info.longitude)\n",
    "pprint(Gonzales_info)\n",
    "pprint(Gonzales_coordinates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All (double check coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Laredo_coordinates)\n",
    "print(Belmont_coordinates)\n",
    "pprint(Gonzales_coordinates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Measuring Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy import distance\n",
    "print(distance.distance(Laredo_coordinates, Belmont_coordinates, Gonzales_coordinates).miles)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mapping GeoPandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "'fiona' in sys.modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as geopd\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating GeoDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GregGeoDF = pd.DataFrame({\n",
    "    'City': ['Laredo', 'Belmont', 'Gonzales'], \n",
    "    'County': ['Webb', 'Midland', 'Gonzales'],\n",
    "    'Latitude':[27.5236998, 31.9803495, 29.4436555, ],\n",
    "    'Longitude':[-99.497352, -102.07359334, -97.5108636]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "greg_gdf = geopd.GeoDataFrame(\n",
    "    GregGeoDF, geometry=geopd.points_from_xy(GregGeoDF.Longitude, GregGeoDF.Latitude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(greg_gdf.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "greg_gdf.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "greg_gdf.plot(marker='o', color = '#00FF00', markersize=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "greg_gdf.to_file('el_Corrido_de_Gregorio_Cortez.shp')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "e528f05ecdbf513f743da5c44906adca99a556c5207201bf3043358644070d32"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
