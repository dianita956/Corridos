{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "source: https://ner.pythonhumanities.com/03_05_generating_custom_word_vectors.html \n",
    "\n",
    "\n",
    "10 Generating Custom Word Vectors with Gensim\n",
    "\n",
    "\n",
    "Dr. W.J.B. Mattingly, Smithsonian Data Science Lab and United States Holocaust Memorial Museum, January 2021\n",
    "\n",
    "\n",
    "adapting method for Corridos Project: 1900 RGV Heros "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = \"../Corridos/corrido corpus/ElCorridodeGregorioCortez_X.txt\"\n",
    "with open (corpus, \"r\", encoding=\"utf-8\") as f:\n",
    "    corpus = f.read()\n",
    "    #print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country karnes, look happened; major sheriff died, leaving román badly wounded. must two afternoon people arrived; said one another, \"it known killed him.\" went around asking questions, half hour afterward, found wrongdoer gregorio cortez. outlawed cortez, throughout whole state; let taken, dead alive; killed several men. said gregorio cortez, pistol hand, \"i don’t regret killed him; regret brother’s death.\" said gregorio cortez, soul aflame, \"i don’t regret killed him; man must defend himself.\" americans coming, whiter dove, fear cortez pistol. americans said, said fearfully, \"come, let us follow trail; wrongdoer cortez.\" set bloodhounds him, could follow trail, trying overtake cortez like following star.. struck gonzales without showing fear, \"follow me, cowardly rangers, gregorio cortez.\" belmont went ranch, succeeded surrounding him, quite three hundred, jumped corral. jumped corral, according hear, got gunfight, killed another sheriff, said gregorio cortez, pistol hand, \"don’t run, cowardly rangers, one mexican.\" gregorio cortez went out, went towards laredo decided follow afraid him. said gregorio cortez, \"what use scheming? cannot catch me, even bloodhounds.\" americans said, \"if catch him, shall do? fight man man, us return.\" el encinal, according hear, made corral, killed another sheriff. said gregorio cortez, shooting lot bullets, \"i weathered thunderstorms; little mist doesn’t bother me.\" met mexican; says haughtily, \"tell news; gregorio cortez.\" \"it said many people killed; surrender things right.\" cortez says jesús, \"at last going see it; go tell rangers come arrest me.\" rangers coming, coming fast even flew, wanted get thousand dollars offered. surrounded house, cortez suddenly appeared them, \"you take i’m willing, way.\" major sheriff said, going cry, \"cortez, hand weapons; going kill.\" said gregorio cortez, shouting loud voice, \"i won’t surrender arms cell.\" said gregorio cortez, said godly voice, \"i won’t surrender arms i’m inside jail.\" taken cortez, matters end, poor family suffering hearts. say farewell, shade cypress tree; end singing ballad cortez.\n"
     ]
    }
   ],
   "source": [
    "stopwords = [\"i\",\"me\",\"my\",\"myself\",\"we\",\"our\",\"ours\",\"ourselves\",\"you\",\"your\",\"yours\",\"yourself\",\"yourselves\",\n",
    "             \"he\",\"him\",\"his\",\"himself\",\"she\",\"her\",\"hers\",\"herself\",\"it\",\"its\",\"itself\",\"they\",\"them\",\"their\",\n",
    "             \"theirs\",\"themselves\",\"what\",\"which\",\"who\",\"whom\",\"this\",\"that\",\"these\",\"those\",\"am\",\"is\",\"are\",\"was\",\n",
    "             \"were\",\"be\",\"been\",\"being\",\"have\",\"has\",\"had\",\"having\",\"do\",\"does\",\"did\",\"doing\",\"a\",\"an\",\"the\",\"and\",\n",
    "             \"but\",\"if\",\"or\",\"because\",\"as\",\"until\",\"while\",\"of\",\"at\",\"by\",\"for\",\"with\",\"about\",\"against\",\"between\",\n",
    "             \"into\",\"through\",\"during\",\"before\",\"after\",\"above\",\"below\",\"to\",\"from\",\"up\",\"down\",\"in\",\"out\",\"on\",\"off\",\n",
    "             \"over\",\"under\",\"again\",\"further\",\"then\",\"once\",\"here\",\"there\",\"when\",\"where\",\"why\",\"how\",\"all\",\"any\",\"both\",\n",
    "             \"each\",\"few\",\"more\",\"most\",\"other\",\"some\",\"such\",\"no\",\"nor\",\"not\",\"only\",\"own\",\"same\",\"so\",\"than\",\"too\",\"very\",\n",
    "             \"s\",\"t\",\"can\",\"will\",\"just\",\"don\",\"should\",\"now\"\n",
    "            ]\n",
    "corpus = corpus.lower()\n",
    "words = corpus.split()\n",
    "\n",
    "new_corpus = []\n",
    "for word in words:\n",
    "    if word not in stopwords:\n",
    "        new_corpus.append(word)\n",
    "\n",
    "corpus = \" \".join(new_corpus)\n",
    "print (corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['country', 'karnes', 'look', 'happened', 'major', 'sheriff', 'died', 'leaving', 'román', 'badly', 'wounded'], ['must', 'two', 'afternoon', 'people', 'arrived', 'said', 'one', 'another', 'it', 'known', 'killed', 'him', 'went', 'around', 'asking', 'questions', 'half', 'hour', 'afterward', 'found', 'wrongdoer', 'gregorio', 'cortez'], ['outlawed', 'cortez', 'throughout', 'whole', 'state', 'let', 'taken', 'dead', 'alive', 'killed', 'several', 'men'], ['said', 'gregorio', 'cortez', 'pistol', 'hand', 'i', 'don’t', 'regret', 'killed', 'him', 'regret', 'brother’s', 'death'], ['said', 'gregorio', 'cortez', 'soul', 'aflame', 'i', 'don’t', 'regret', 'killed', 'him', 'man', 'must', 'defend', 'himself'], ['americans', 'coming', 'whiter', 'dove', 'fear', 'cortez', 'pistol'], ['americans', 'said', 'said', 'fearfully', 'come', 'let', 'us', 'follow', 'trail', 'wrongdoer', 'cortez'], ['set', 'bloodhounds', 'him', 'could', 'follow', 'trail', 'trying', 'overtake', 'cortez', 'like', 'following', 'star', 'struck', 'gonzales', 'without', 'showing', 'fear', 'follow', 'me', 'cowardly', 'rangers', 'gregorio', 'cortez'], ['belmont', 'went', 'ranch', 'succeeded', 'surrounding', 'him', 'quite', 'three', 'hundred', 'jumped', 'corral'], ['jumped', 'corral', 'according', 'hear', 'got', 'gunfight', 'killed', 'another', 'sheriff', 'said', 'gregorio', 'cortez', 'pistol', 'hand', 'don’t', 'run', 'cowardly', 'rangers', 'one', 'mexican'], ['gregorio', 'cortez', 'went', 'out', 'went', 'towards', 'laredo', 'decided', 'follow', 'afraid', 'him'], ['said', 'gregorio', 'cortez', 'what', 'use', 'scheming'], ['cannot', 'catch', 'me', 'even', 'bloodhounds'], ['americans', 'said', 'if', 'catch', 'him', 'shall', 'do'], ['fight', 'man', 'man', 'us', 'return'], ['el', 'encinal', 'according', 'hear', 'made', 'corral', 'killed', 'another', 'sheriff'], ['said', 'gregorio', 'cortez', 'shooting', 'lot', 'bullets', 'i', 'weathered', 'thunderstorms', 'little', 'mist', 'doesn’t', 'bother', 'me', 'met', 'mexican', 'says', 'haughtily', 'tell', 'news', 'gregorio', 'cortez'], ['it', 'said', 'many', 'people', 'killed', 'surrender', 'things', 'right'], ['cortez', 'says', 'jesús', 'at', 'last', 'going', 'see', 'it', 'go', 'tell', 'rangers', 'come', 'arrest', 'me'], ['rangers', 'coming', 'coming', 'fast', 'even', 'flew', 'wanted', 'get', 'thousand', 'dollars', 'offered'], ['surrounded', 'house', 'cortez', 'suddenly', 'appeared', 'them', 'you', 'take', 'i’m', 'willing', 'way'], ['major', 'sheriff', 'said', 'going', 'cry', 'cortez', 'hand', 'weapons', 'going', 'kill'], ['said', 'gregorio', 'cortez', 'shouting', 'loud', 'voice', 'i', 'won’t', 'surrender', 'arms', 'cell'], ['said', 'gregorio', 'cortez', 'said', 'godly', 'voice', 'i', 'won’t', 'surrender', 'arms', 'i’m', 'inside', 'jail'], ['taken', 'cortez', 'matters', 'end', 'poor', 'family', 'suffering', 'hearts'], ['say', 'farewell', 'shade', 'cypress', 'tree', 'end', 'singing', 'ballad', 'cortez']]\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import string\n",
    "import json\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "doc = nlp(corpus)\n",
    "\n",
    "sentences = []\n",
    "for sent in doc.sents:\n",
    "    sentence = sent.text.translate(str.maketrans('', '', string.punctuation))\n",
    "    words = sentence.split()\n",
    "    sentences.append(words)\n",
    "print (sentences)\n",
    "\n",
    "out_file = open(\"../Corridos/data/GregCortez.json\", \"w\")\n",
    "json.dump(sentences, out_file, indent=4)\n",
    "out_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function training at 0x0000027C33B59700>\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.word2vec import Word2Vec\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "from collections import defaultdict\n",
    "\n",
    "model_name = \"corrido_ner_model_01\"\n",
    "\n",
    "def training(model_name):\n",
    "    with open(\"data/GregCortez.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "        texts = json.load(f)\n",
    "        #print(texts)\n",
    "        sentences = texts\n",
    "        w2v_model = Word2Vec(min_count=1,\n",
    "                window=2,\n",
    "                vector_size=500, #(size of the vocab, 300-500) parameters\n",
    "                sample=6e-5,\n",
    "                alpha=0.03,\n",
    "                min_alpha=0.0007,\n",
    "                negative=20)\n",
    "\n",
    "    w2v_model.build_vocab(sentences, progress_per=10000)\n",
    "    w2v_model.train(sentences, total_examples=w2v_model.corpus_count, epochs=30, report_delay=1)\n",
    "    w2v_model.save(f\"../Corridos/word vectors/{model_name}.model\")\n",
    "    w2v_model.wv.save_word2vec_format(f\"../Corridos/word vectors/word2vec_{model_name}.txt\")\n",
    "\n",
    "training(\"corrido_ner_model_01\") \n",
    "print(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_wordvecs(corpus, model_name):\n",
    "    \n",
    "    print(corpus)\n",
    "    print(model_name)\n",
    "    print (len(corpus))\n",
    "    \n",
    "\n",
    "    phrases = Phrases(corpus, min_count=30, progress_per=10000)\n",
    "    print (\"Made Phrases\")\n",
    "    \n",
    "    bigram = Phraser(phrases)\n",
    "    print (\"Made Bigrams\")\n",
    "    \n",
    "    sentences = phrases[corpus]\n",
    "    print (\"Found sentences\")\n",
    "    word_freq = defaultdict(int)\n",
    "\n",
    "    for sent in sentences:\n",
    "        for i in sent:\n",
    "            word_freq[i]+=1\n",
    "\n",
    "    print (len(word_freq))\n",
    "    \n",
    "    print (\"Training model now...\")\n",
    "\n",
    "\n",
    "create_wordvecs(sentences, \"corrido_word_vecs_01\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open (\"data/word_vecs.txt\", \"r\") as f:\n",
    "    data = f.readlines()\n",
    "    print (data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data[1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. Loading Custom Word Vectors into a spaCy Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_word_vectors(model_name, word_vectors):\n",
    "    import spacy\n",
    "    import subprocess\n",
    "    import sys\n",
    "    print(model_name)\n",
    "    #print(word_vectors)\n",
    "    subprocess.run([sys.executable,\n",
    "                    \"-m\",\n",
    "                    \"spacy\",\n",
    "                    \"init-model\",\n",
    "                    \"en\",\n",
    "                    model_name,\n",
    "                    \"--vectors-loc\",\n",
    "                    word_vectors\n",
    "                        ]\n",
    "                    )\n",
    "    print (f\"New spaCy model created with word vectors. File: {model_name}\")\n",
    "load_word_vectors(model_name, word_vectors)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Greg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c33b8046986a03aa44ef4ea500a2630dcd79ff60fec54402ff1309c4dcbd3e63"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
