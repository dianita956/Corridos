{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = \"../Corridos/corrido corpus/ElCorridodeGregorioCortez_X.txt\"\n",
    "with open (corpus, \"r\", encoding=\"utf-8\") as f:\n",
    "    corpus = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country karnes, look happened; major sheriff died, leaving román badly wounded. must two afternoon people arrived; said one another, \"it known killed him.\" went around asking questions, half hour afterward, found wrongdoer gregorio cortez. outlawed cortez, throughout whole state; let taken, dead alive; killed several men. said gregorio cortez, pistol hand, \"i don’t regret killed him; regret brother’s death.\" said gregorio cortez, soul aflame, \"i don’t regret killed him; man must defend himself.\" americans coming, whiter dove, fear cortez pistol. americans said, said fearfully, \"come, let us follow trail; wrongdoer cortez.\" set bloodhounds him, could follow trail, trying overtake cortez like following star.. struck gonzales without showing fear, \"follow me, cowardly rangers, gregorio cortez.\" belmont went ranch, succeeded surrounding him, quite three hundred, jumped corral. jumped corral, according hear, got gunfight, killed another sheriff, said gregorio cortez, pistol hand, \"don’t run, cowardly rangers, one mexican.\" gregorio cortez went out, went towards laredo decided follow afraid him. said gregorio cortez, \"what use scheming? cannot catch me, even bloodhounds.\" americans said, \"if catch him, shall do? fight man man, us return.\" el encinal, according hear, made corral, killed another sheriff. said gregorio cortez, shooting lot bullets, \"i weathered thunderstorms; little mist doesn’t bother me.\" met mexican; says haughtily, \"tell news; gregorio cortez.\" \"it said many people killed; surrender things right.\" cortez says jesús, \"at last going see it; go tell rangers come arrest me.\" rangers coming, coming fast even flew, wanted get thousand dollars offered. surrounded house, cortez suddenly appeared them, \"you take i’m willing, way.\" major sheriff said, going cry, \"cortez, hand weapons; going kill.\" said gregorio cortez, shouting loud voice, \"i won’t surrender arms cell.\" said gregorio cortez, said godly voice, \"i won’t surrender arms i’m inside jail.\" taken cortez, matters end, poor family suffering hearts. say farewell, shade cypress tree; end singing ballad cortez.\n"
     ]
    }
   ],
   "source": [
    "stopwords = [\"i\",\"me\",\"my\",\"myself\",\"we\",\"our\",\"ours\",\"ourselves\",\"you\",\"your\",\"yours\",\"yourself\",\"yourselves\",\n",
    "             \"he\",\"him\",\"his\",\"himself\",\"she\",\"her\",\"hers\",\"herself\",\"it\",\"its\",\"itself\",\"they\",\"them\",\"their\",\n",
    "             \"theirs\",\"themselves\",\"what\",\"which\",\"who\",\"whom\",\"this\",\"that\",\"these\",\"those\",\"am\",\"is\",\"are\",\"was\",\n",
    "             \"were\",\"be\",\"been\",\"being\",\"have\",\"has\",\"had\",\"having\",\"do\",\"does\",\"did\",\"doing\",\"a\",\"an\",\"the\",\"and\",\n",
    "             \"but\",\"if\",\"or\",\"because\",\"as\",\"until\",\"while\",\"of\",\"at\",\"by\",\"for\",\"with\",\"about\",\"against\",\"between\",\n",
    "             \"into\",\"through\",\"during\",\"before\",\"after\",\"above\",\"below\",\"to\",\"from\",\"up\",\"down\",\"in\",\"out\",\"on\",\"off\",\n",
    "             \"over\",\"under\",\"again\",\"further\",\"then\",\"once\",\"here\",\"there\",\"when\",\"where\",\"why\",\"how\",\"all\",\"any\",\"both\",\n",
    "             \"each\",\"few\",\"more\",\"most\",\"other\",\"some\",\"such\",\"no\",\"nor\",\"not\",\"only\",\"own\",\"same\",\"so\",\"than\",\"too\",\"very\",\n",
    "             \"s\",\"t\",\"can\",\"will\",\"just\",\"don\",\"should\",\"now\"\n",
    "            ]\n",
    "corpus = corpus.lower()\n",
    "words = corpus.split()\n",
    "\n",
    "new_corpus = []\n",
    "for word in words:\n",
    "    if word not in stopwords:\n",
    "        new_corpus.append(word)\n",
    "\n",
    "corpus = \" \".join(new_corpus)\n",
    "print (corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['country', 'karnes', 'look', 'happened', 'major', 'sheriff', 'died', 'leaving', 'román', 'badly', 'wounded'], ['must', 'two', 'afternoon', 'people', 'arrived', 'said', 'one', 'another', 'it', 'known', 'killed', 'him', 'went', 'around', 'asking', 'questions', 'half', 'hour', 'afterward', 'found', 'wrongdoer', 'gregorio', 'cortez'], ['outlawed', 'cortez', 'throughout', 'whole', 'state', 'let', 'taken', 'dead', 'alive', 'killed', 'several', 'men'], ['said', 'gregorio', 'cortez', 'pistol', 'hand', 'i', 'don’t', 'regret', 'killed', 'him', 'regret', 'brother’s', 'death'], ['said', 'gregorio', 'cortez', 'soul', 'aflame', 'i', 'don’t', 'regret', 'killed', 'him', 'man', 'must', 'defend', 'himself'], ['americans', 'coming', 'whiter', 'dove', 'fear', 'cortez', 'pistol'], ['americans', 'said', 'said', 'fearfully', 'come', 'let', 'us', 'follow', 'trail', 'wrongdoer', 'cortez'], ['set', 'bloodhounds', 'him', 'could', 'follow', 'trail', 'trying', 'overtake', 'cortez', 'like', 'following', 'star', 'struck', 'gonzales', 'without', 'showing', 'fear', 'follow', 'me', 'cowardly', 'rangers', 'gregorio', 'cortez'], ['belmont', 'went', 'ranch', 'succeeded', 'surrounding', 'him', 'quite', 'three', 'hundred', 'jumped', 'corral'], ['jumped', 'corral', 'according', 'hear', 'got', 'gunfight', 'killed', 'another', 'sheriff', 'said', 'gregorio', 'cortez', 'pistol', 'hand', 'don’t', 'run', 'cowardly', 'rangers', 'one', 'mexican'], ['gregorio', 'cortez', 'went', 'out', 'went', 'towards', 'laredo', 'decided', 'follow', 'afraid', 'him'], ['said', 'gregorio', 'cortez', 'what', 'use', 'scheming'], ['cannot', 'catch', 'me', 'even', 'bloodhounds'], ['americans', 'said', 'if', 'catch', 'him', 'shall', 'do'], ['fight', 'man', 'man', 'us', 'return'], ['el', 'encinal', 'according', 'hear', 'made', 'corral', 'killed', 'another', 'sheriff'], ['said', 'gregorio', 'cortez', 'shooting', 'lot', 'bullets', 'i', 'weathered', 'thunderstorms', 'little', 'mist', 'doesn’t', 'bother', 'me', 'met', 'mexican', 'says', 'haughtily', 'tell', 'news', 'gregorio', 'cortez'], ['it', 'said', 'many', 'people', 'killed', 'surrender', 'things', 'right'], ['cortez', 'says', 'jesús', 'at', 'last', 'going', 'see', 'it', 'go', 'tell', 'rangers', 'come', 'arrest', 'me'], ['rangers', 'coming', 'coming', 'fast', 'even', 'flew', 'wanted', 'get', 'thousand', 'dollars', 'offered'], ['surrounded', 'house', 'cortez', 'suddenly', 'appeared', 'them', 'you', 'take', 'i’m', 'willing', 'way'], ['major', 'sheriff', 'said', 'going', 'cry', 'cortez', 'hand', 'weapons', 'going', 'kill'], ['said', 'gregorio', 'cortez', 'shouting', 'loud', 'voice', 'i', 'won’t', 'surrender', 'arms', 'cell'], ['said', 'gregorio', 'cortez', 'said', 'godly', 'voice', 'i', 'won’t', 'surrender', 'arms', 'i’m', 'inside', 'jail'], ['taken', 'cortez', 'matters', 'end', 'poor', 'family', 'suffering', 'hearts'], ['say', 'farewell', 'shade', 'cypress', 'tree', 'end', 'singing', 'ballad', 'cortez']]\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import string\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "doc = nlp(corpus)\n",
    "\n",
    "sentences = []\n",
    "for sent in doc.sents:\n",
    "    sentence = sent.text.translate(str.maketrans('', '', string.punctuation))\n",
    "    words = sentence.split()\n",
    "    sentences.append(words)\n",
    "print (sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n",
      "Made Phrases\n",
      "Made Bigrams\n",
      "Found sentences\n",
      "182\n",
      "Training model now...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 36\u001b[0m\n\u001b[0;32m     34\u001b[0m     w2v_model\u001b[39m.\u001b[39mtrain(sentences, total_examples\u001b[39m=\u001b[39mw2v_model\u001b[39m.\u001b[39mcorpus_count, epochs\u001b[39m=\u001b[39m\u001b[39m30\u001b[39m, report_delay\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m     35\u001b[0m     w2v_model\u001b[39m.\u001b[39mwv\u001b[39m.\u001b[39msave_word2vec_format(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdata/\u001b[39m\u001b[39m{\u001b[39;00mmodel_name\u001b[39m}\u001b[39;00m\u001b[39m.txt\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 36\u001b[0m create_wordvecs(sentences, \u001b[39m\"\u001b[39;49m\u001b[39mword_vecs\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "Cell \u001b[1;32mIn[9], line 26\u001b[0m, in \u001b[0;36mcreate_wordvecs\u001b[1;34m(corpus, model_name)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[39mprint\u001b[39m (\u001b[39mlen\u001b[39m(word_freq))\n\u001b[0;32m     25\u001b[0m \u001b[39mprint\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39mTraining model now...\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 26\u001b[0m w2v_model \u001b[39m=\u001b[39m Word2Vec(min_count\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[0;32m     27\u001b[0m                     window\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m,\n\u001b[0;32m     28\u001b[0m                     size\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m,\n\u001b[0;32m     29\u001b[0m                     sample\u001b[39m=\u001b[39;49m\u001b[39m6e-5\u001b[39;49m,\n\u001b[0;32m     30\u001b[0m                     alpha\u001b[39m=\u001b[39;49m\u001b[39m0.03\u001b[39;49m,\n\u001b[0;32m     31\u001b[0m                     min_alpha\u001b[39m=\u001b[39;49m\u001b[39m0.0007\u001b[39;49m,\n\u001b[0;32m     32\u001b[0m                     negative\u001b[39m=\u001b[39;49m\u001b[39m20\u001b[39;49m)\n\u001b[0;32m     33\u001b[0m w2v_model\u001b[39m.\u001b[39mbuild_vocab(sentences, progress_per\u001b[39m=\u001b[39m\u001b[39m10000\u001b[39m)\n\u001b[0;32m     34\u001b[0m w2v_model\u001b[39m.\u001b[39mtrain(sentences, total_examples\u001b[39m=\u001b[39mw2v_model\u001b[39m.\u001b[39mcorpus_count, epochs\u001b[39m=\u001b[39m\u001b[39m30\u001b[39m, report_delay\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'size'"
     ]
    }
   ],
   "source": [
    "def create_wordvecs(corpus, model_name):\n",
    "    from gensim.models.word2vec import Word2Vec\n",
    "    from gensim.models.phrases import Phrases, Phraser\n",
    "    from collections import defaultdict\n",
    "    \n",
    "    print (len(corpus))\n",
    "    \n",
    "\n",
    "    phrases = Phrases(corpus, min_count=30, progress_per=10000)\n",
    "    print (\"Made Phrases\")\n",
    "    \n",
    "    bigram = Phraser(phrases)\n",
    "    print (\"Made Bigrams\")\n",
    "    \n",
    "    sentences = phrases[corpus]\n",
    "    print (\"Found sentences\")\n",
    "    word_freq = defaultdict(int)\n",
    "\n",
    "    for sent in sentences:\n",
    "        for i in sent:\n",
    "            word_freq[i]+=1\n",
    "\n",
    "    print (len(word_freq))\n",
    "    \n",
    "    print (\"Training model now...\")\n",
    "    w2v_model = Word2Vec(min_count=1,\n",
    "                        window=2,\n",
    "                        size=100,\n",
    "                        sample=6e-5,\n",
    "                        alpha=0.03,\n",
    "                        min_alpha=0.0007,\n",
    "                        negative=20)\n",
    "    w2v_model.build_vocab(sentences, progress_per=10000)\n",
    "    w2v_model.train(sentences, total_examples=w2v_model.corpus_count, epochs=30, report_delay=1)\n",
    "    w2v_model.wv.save_word2vec_format(f\"data/{model_name}.txt\")\n",
    "create_wordvecs(sentences, \"word_vecs\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Greg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c33b8046986a03aa44ef4ea500a2630dcd79ff60fec54402ff1309c4dcbd3e63"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
